---
title: "Causal Inference of mobility and municipal effects on the transmission of COVID-19"
author: "Lasse Hansen"
date: "11/21/2020"
output: html_document
---

```{r Loading Packages}
pacman::p_load(tidyverse, purrr, tidyr, stringr, Boruta, ggplot2)
pacman::p_load(sandwich, survival, zoo, lmtest, car, carData, AER, nlme, ggpubr)
```

## Scraping data
### First I will create a series of functions that can take raw DMI data and make it into panel data for analysis
#### Preprocessing function
```{r}
PreProcessing1 <- function(dataframe) {
humid <- dataframe[grepl("humidity_past1h", dataframe$V2),]
temp <- dataframe[grepl("temp_mean_past1h", dataframe$V2),]
wind <- dataframe[grepl("wind_speed_past1h", dataframe$V2),]
precip <-  dataframe[grepl("precip_dur_past1h", dataframe$V2),]
sun <- dataframe[grepl("sun_last1h_glob", dataframe$V2),]

d <- rbind(humid, temp, wind, precip, sun)

d$stationID <- gsub("stationId:", "", d$V3)
d$stationID <- as.numeric(d$stationID)
d$parameterId <- gsub("parameterId:", "", d$V2)
d$value <- gsub("value:|}", "", d$V6)
d$value <- as.numeric(d$value)
data <- subset(d, select = c(stationID, parameterId, timeObs, value), subset = stationID >=5000 & stationID <=34000)
return(data)
}
```

#### Regex function for getting station ID's
```{r Using regex}
regex_s <- function(dataframe) {
  vars <-  str_match(dataframe$timeObs, "(\\d+-\\d+-\\d+) (\\d+)")
  vars <-  as.data.frame(vars)
  vars <- vars[, -1]
  names(vars) <- c("Date", "Time")
  d <- cbind(vars, data.frame(dataframe$stationID, dataframe$parameterId, dataframe$value))
  colnames(d) <- c("Date", "Time", "stationID", "parameterId", "value")
  return(d)
}
```


#### Station to kommune function
```{r Station to kommune function}
Station_To_Kommune <- function(dataframe) {
  
dataframe$Kommune <- ifelse(dataframe$stationID == 5005, "Hjørring",
ifelse(dataframe$stationID == 5009, "Hjørring",
ifelse(dataframe$stationID == 5031, "Læsø",
ifelse(dataframe$stationID == 5035, "Frederikshavn",
ifelse(dataframe$stationID == 5042, "Aalborg",
ifelse(dataframe$stationID == 5065, "Rebild",
ifelse(dataframe$stationID == 5070, "Mariagerfjord",
ifelse(dataframe$stationID == 5075, "Fredericia",
ifelse(dataframe$stationID == 5081, "Vesthimmerlands",
ifelse(dataframe$stationID == 5085, "Vesthimmerlands",
ifelse(dataframe$stationID == 5089, "Thisted",
ifelse(dataframe$stationID == 5095, "Thisted",
ifelse(dataframe$stationID == 5105, "Morsø",
ifelse(dataframe$stationID == 5109, "Skive",
ifelse(dataframe$stationID == 5135, "Silkeborg",
ifelse(dataframe$stationID == 5140, "Randers",
ifelse(dataframe$stationID == 5150, "Norddjurs",
ifelse(dataframe$stationID == 5160, "Kerteminde",
ifelse(dataframe$stationID == 5165, "Samsø",
ifelse(dataframe$stationID == 5169, "Odder",
ifelse(dataframe$stationID == 5185, "Skanderborg",
ifelse(dataframe$stationID == 5199, "Ikast-Brande",
ifelse(dataframe$stationID == 5205, "Horsens",
ifelse(dataframe$stationID == 5220, "Hedensted",
ifelse(dataframe$stationID == 5269, "Ikast-Brande",
ifelse(dataframe$stationID == 5272, "Ikast-Brande", dataframe$stationID ))))))))))))))))))))))))))


dataframe$Kommune <- ifelse(dataframe$stationID == 5276, "Herning",
ifelse(dataframe$stationID == 5277, "Herning",
ifelse(dataframe$stationID == 5290, "Struer",
ifelse(dataframe$stationID == 5300, "Viborg",
ifelse(dataframe$stationID == 5305, "Ringkøbing-Skjern",
ifelse(dataframe$stationID == 5320, "Varde",
ifelse(dataframe$stationID == 5329, "Varde",
ifelse(dataframe$stationID == 5343, "Vejen",
ifelse(dataframe$stationID == 5345, "Esbjerg",
ifelse(dataframe$stationID == 5350, "Tønder",
ifelse(dataframe$stationID == 5355, "Tønder",
ifelse(dataframe$stationID == 5365, "Aabenraa",
ifelse(dataframe$stationID == 5375, "Nordfyns",
ifelse(dataframe$stationID == 5381, "Tønder",
ifelse(dataframe$stationID == 5395, "Haderslev",
ifelse(dataframe$stationID == 5400, "Middelfart",
ifelse(dataframe$stationID == 5406, "Nordfyns",
ifelse(dataframe$stationID == 5408, "Odense",
ifelse(dataframe$stationID == 5435, "Faaborg-Midtfyn",
ifelse(dataframe$stationID == 5450, "Langeland",
ifelse(dataframe$stationID == 5469, "Nyborg",
ifelse(dataframe$stationID == 5499, "Ringsted",
ifelse(dataframe$stationID == 5510, "Skanderborg",
ifelse(dataframe$stationID == 5537, "Holbæk",
ifelse(dataframe$stationID == 5545, "Furesø",
ifelse(dataframe$stationID == 5575, "Gribskov",
ifelse(dataframe$stationID == 5735, "København",
ifelse(dataframe$stationID == 5880, "Slagelse", dataframe$Kommune ))))))))))))))))))))))))))))
       

dataframe$Kommune <- ifelse(dataframe$stationID == 5889, "Faxe",
ifelse(dataframe$stationID == 5935, "Vordingborg",
ifelse(dataframe$stationID == 5945, "Vordingborg",
ifelse(dataframe$stationID == 5970, "Lolland",
ifelse(dataframe$stationID == 5986, "Vordingborg",
ifelse(dataframe$stationID == 5994, "Bornholm",
ifelse(dataframe$stationID == 6019, "Thisted",
ifelse(dataframe$stationID == 6031, "Aalborg",
ifelse(dataframe$stationID == 6032, "Aarhus",
ifelse(dataframe$stationID == 6041, "Frederikshavn",
ifelse(dataframe$stationID == 6049, "Viborg",
ifelse(dataframe$stationID == 6051, "Thisted",
ifelse(dataframe$stationID == 6056, "Holstebro",
ifelse(dataframe$stationID == 6058, "Ringkøbing-Skjern",
ifelse(dataframe$stationID == 6065, "Vesthimmerlands",
ifelse(dataframe$stationID == 6068, "Ikast-Brande",
ifelse(dataframe$stationID == 6072, "Favrskov",
ifelse(dataframe$stationID == 6073, "Syddjurs",
ifelse(dataframe$stationID == 6074, "Aarhus",
ifelse(dataframe$stationID == 6079, "Norddjurs",
ifelse(dataframe$stationID == 6081, "Varde",
ifelse(dataframe$stationID == 6082, "Ringkøbing-Skjern",
ifelse(dataframe$stationID == 6088, "Fanø",
ifelse(dataframe$stationID == 6093, "Esbjerg",
ifelse(dataframe$stationID == 6096, "Tønder",
ifelse(dataframe$stationID == 6102, "Horsens",
ifelse(dataframe$stationID == 6116, "Aabenraa",
ifelse(dataframe$stationID == 6119, "Sønderborg", dataframe$Kommune ))))))))))))))))))))))))))))
       
dataframe$Kommune <- ifelse(dataframe$stationID == 6123, "Assens",
ifelse(dataframe$stationID == 6124, "Svendborg",
ifelse(dataframe$stationID == 6126, "Faaborg-Midtfyn",
ifelse(dataframe$stationID == 6132, "Samsø",
ifelse(dataframe$stationID == 6135, "Slagelse",
ifelse(dataframe$stationID == 6136, "Slagelse",
ifelse(dataframe$stationID == 6138, "Vordingborg",
ifelse(dataframe$stationID == 6141, "Lolland",
ifelse(dataframe$stationID == 6147, "Vordingborg",
ifelse(dataframe$stationID == 6149, "Guldborgsund",
ifelse(dataframe$stationID == 6151, "Slagelse",
ifelse(dataframe$stationID == 6154, "Næstved",
ifelse(dataframe$stationID == 6156, "Holbæk",
ifelse(dataframe$stationID == 6159, "Kalundborg",
ifelse(dataframe$stationID == 6168, "Gribskov",
ifelse(dataframe$stationID == 6169, "Odsherred",
ifelse(dataframe$stationID == 6174, "Køge",
ifelse(dataframe$stationID == 6181, "Gentofte",
ifelse(dataframe$stationID == 6183, "Tårnby",
ifelse(dataframe$stationID == 6184, "DMI",
ifelse(dataframe$stationID == 6186, "Frederiksberg",
ifelse(dataframe$stationID == 6187, "Kalundborg",
ifelse(dataframe$stationID == 6188, "København",
ifelse(dataframe$stationID == 6193, "Bornholm",
ifelse(dataframe$stationID == 6197, "Bornholm", dataframe$Kommune )))))))))))))))))))))))))

dataframe$Kommune <- ifelse(dataframe$stationID == 5202, "Ikast-Brande",
ifelse(dataframe$stationID == 5225, "Aarhus",
ifelse(dataframe$stationID == 5440, "Svendborg",
ifelse(dataframe$stationID == 5455, "Langeland",
ifelse(dataframe$stationID == 5505, "Høje-Taastrup", dataframe$Kommune)))))

return(dataframe)
}
```


#### Function that combines the above ones and groups by each station, date and parameter

```{r}
PreProc <- function(filename) {
  data <- read.delim(paste0("/Users/lassehansen/Desktop/Lasse/Cognitive Science 3 Semester/Causal Inference/Causal-Inference/DMI/", filename), sep = ",", header = F)
  data$timeObs <-  gsub("timeObserved:", "", data$V5)
  data$timeObs <- as.numeric(data$timeObs)/10^6
  data$timeObs <- as.POSIXct(data$timeObs, origin = "1970-01-01", tz = "GMT")
  data <- PreProcessing1(data)
  data <-  regex_s(data)
  data <- data %>% 
        select(Date, Time, stationID, parameterId, value) %>% 
        group_by(Date, parameterId, stationID) %>% 
        summarise(
          DayValue_Param = mean(value, na.rm = T),
        ) %>% 
        spread(., key = parameterId, value = DayValue_Param)
  data$stationID <- as.numeric(data$stationID)
  data = Station_To_Kommune(data)
  return(data)
}
```

#### Using map_df, which is a function that can load in 6 different zip-files containing raw data at ones

```{r Using function}
data <- list.files(path = "/Users/lassehansen/Desktop/Lasse/Cognitive Science 3 Semester/Causal Inference/Causal-Inference/DMI/", pattern = ".txt") %>%
    purrr::map_df(PreProc)
```

#### Reading in google mobility data

```{r Making mobility data from google}
mobility <- read_csv("2020_DK_Region_Mobility_Report.csv")

mobility$CountDate <- as.numeric(mobility$date)

mobility$sub_region_2 <- gsub(" Municipality", "", mobility$sub_region_2)
mobility$sub_region_2 <- gsub(" ", "", mobility$sub_region_2)

mobility$sub_region_2 <- ifelse(mobility$sub_region_1 == "Capital Region of Denmark" & is.na(mobility$sub_region_2), "København", mobility$sub_region_2)

mobility$sub_region_2 <- ifelse(mobility$sub_region_1 == "Central Denmark Region" & is.na(mobility$sub_region_2), "Samsø", mobility$sub_region_2)

mobility$sub_region_2 <- ifelse(mobility$sub_region_1 == "North Denmark Region" & is.na(mobility$sub_region_2), "Læsø", mobility$sub_region_2)

mobility$sub_region_2 <- ifelse(mobility$sub_region_1 == "Region Zealand" & is.na(mobility$sub_region_2), "Christiansø", mobility$sub_region_2)

mobility$sub_region_2 <- ifelse(mobility$sub_region_1 == "Region of Southern Denmark" & is.na(mobility$sub_region_2), "Ærø", mobility$sub_region_2)

mobility$sub_region_2 <- ifelse(is.na(mobility$sub_region_1) & is.na(mobility$sub_region_2), "Fanø", mobility$sub_region_2)

mobility$sub_region_2 <- ifelse(mobility$sub_region_2 == "Vesthimmerland", "Vesthimmerlands", mobility$sub_region_2)

mobility$sub_region_2 <- ifelse(mobility$sub_region_2 == "Brondby", "Brøndby", mobility$sub_region_2)

mobility$sub_region_2 <- ifelse(mobility$sub_region_2 == "Copenhagen", "København", mobility$sub_region_2)

mobility$sub_region_2 <- ifelse(mobility$sub_region_2 == "Nordfyn", "Nordfyns", mobility$sub_region_2)

mobility$sub_region_1 <- ifelse(mobility$sub_region_2 == "Fanø", "Region of Southern Denmark", mobility$sub_region_1)

mobility <- mobility %>% filter(CountDate >= 18383 & CountDate <= 18596)

mobility <- mobility %>% select(date, sub_region_1, sub_region_2, residential_percent_change_from_baseline, workplaces_percent_change_from_baseline, transit_stations_percent_change_from_baseline, retail_and_recreation_percent_change_from_baseline, parks_percent_change_from_baseline, grocery_and_pharmacy_percent_change_from_baseline)

colnames(mobility) <- c("Date", "Region", "Kommune", "Residential", "Workplace", "Transit", "Retail", "Park", "Grocery")

mobility$Date <- as.factor(mobility$Date)

mobility1 <- merge(data3, mobility, by = c("Kommune", "Date"))
```

#### Grouping by region and date so that each municipality will get data from the region they are in per date

```{r Getting mobility per region}
mobility2 <- mobility1 %>% group_by(Date, Region) %>% summarise(
    Workplace = mean(Workplace, na.rm = T),
    Residential = mean(Residential, na.rm = T),
    Transit = mean(Transit, na.rm = T),
    Retail = mean(Retail, na.rm = T),
    Park = mean(Park, na.rm = T),
    Grocery = mean(Grocery, na.rm = T),
    Kommune = Kommune
    ) %>% ungroup()

mobility3 <- mobility2 %>%  ungroup() %>% group_by(Date, Kommune) %>% summarise(
    Workplace = mean(Workplace, na.rm = T),
    Residential = mean(Residential, na.rm = T),
    Transit = mean(Transit, na.rm = T),
    Retail = mean(Retail, na.rm = T),
    Park = mean(Park, na.rm = T),
    Grocery = mean(Grocery, na.rm = T),
    Region = Region
      )
```

#### Now I merge mobility data and weather data for each municipality

```{r Taking mean of weather variables per weather station in municipalities}
kommune  <- read.csv("Kommuneposition (1).csv", sep = ";")

data1 <- full_join(data10, kommune, by = "Kommune", "Date")

data1$Kolonne1 <- ifelse(is.na(data1$Kolonne1.x), data1$Kolonne1.y, data1$Kolonne1.x)
data1$Kolonne1.y <- NULL
data1$Kolonne1.x <- NULL

data1 <- filter(data1, Kommune != "DMI")

data3 <- data1 %>% 
  select(Date, Kommune, humidity_past1h, precip_dur_past1h, sun_last1h_glob, temp_mean_past1h, Kolonne1, wind_speed_past1h) %>% 
  group_by(Kolonne1, Date) %>% 
  summarise(
    Humid = mean(humidity_past1h, na.rm = T),
    Precip = mean(precip_dur_past1h, na.rm = T),
    Sun = mean(sun_last1h_glob, na.rm = T),
    Temp = mean(temp_mean_past1h, na.rm = T),
    Wind = mean(wind_speed_past1h, na.rm = T),
    Kommune = Kommune
            )

data3 <- data3 %>% 
  group_by(Date, Kommune) %>% 
  summarise(
    Humid = mean(Humid, na.rm = T),
    Precip = mean(Precip, na.rm = T),
    Sun = mean(Sun, na.rm = T),
    Temp = mean(Temp, na.rm = T),
    Wind = mean(Wind, na.rm = T),
            )

data4 <- left_join(mobility3, data3, by = c("Kommune" = "Kommune", "Date" = "Date"))
```

#### Loading in data from SSI, then turning it into number of cases per test per municipality on each day

```{r Getting ammount of testet and number of cases per municipality and merging with df}
testet <- read.csv("Municipality_tested_persons_time_series.csv", sep = ";")
testet <- testet[complete.cases(testet), ]
testet$NA. <- NULL
testet$Christiansø <- NULL
testet <- testet %>% pivot_longer(., 2:99)
testet <- testet[8037:29008, ]
colnames(testet) <- c("Date", "Kommune", "Tests")
testet$Kommune <- ifelse(testet$Kommune == "Copenhagen", "København",
                  ifelse(testet$Kommune == "Høje.Taastrup", "Høje-Taastrup",
                  ifelse(testet$Kommune == "Lyngby.Taarbæk", "Lyngby-Taarbæk",
                  ifelse(testet$Kommune == "Faaborg.Midtfyn", "Faaborg-Midtfyn",
                  ifelse(testet$Kommune == "Ikast.Brande", "Ikast-Brande",
                  ifelse(testet$Kommune == "Ringkøbing.Skjern", "Ringkøbing-Skjern",
                  ifelse(testet$Kommune == "Copenhagen", "København", testet$Kommune
                         )))))))


positive <- read.csv("Municipality_cases_time_series.csv", sep = ";")
positive$NA. <- NULL

positive <- positive[complete.cases(positive), ]
positive <- positive %>% pivot_longer(., 2:99)
positive <- positive[6273:27244, ]
colnames(positive) <- c("Date", "Kommune", "Cases")

positive$Kommune <- ifelse(positive$Kommune == "Copenhagen", "København",
                  ifelse(positive$Kommune == "Høje.Taastrup", "Høje-Taastrup",
                  ifelse(positive$Kommune == "Lyngby.Taarbæk", "Lyngby-Taarbæk",
                  ifelse(positive$Kommune == "Faaborg.Midtfyn", "Faaborg-Midtfyn",
                  ifelse(positive$Kommune == "Ikast.Brande", "Ikast-Brande",
                  ifelse(positive$Kommune == "Ringkøbing.Skjern", "Ringkøbing-Skjern",
                  ifelse(positive$Kommune == "Copenhagen", "København", positive$Kommune
                         )))))))

d <- full_join(testet, positive, by = c("Kommune", "Date"))
d$CasePerTest <- (d$Cases/d$Tests)*100
d$CasePerTest <- ifelse(d$CasePerTest == "NaN", 0, d$CasePerTest)

data4 <- full_join(data4, d, by = c("Kommune", "Date"))

data4 <- subset(data4, Kommune != "DMI")
data4 <- subset(data4, Kommune != "Christiansø")
```

#### Filtering out dates not useable for analysis

```{r Filtering by date}
data4$CountDate <- as.numeric(data4$Date)
data4 <- data4 %>% filter(CountDate >= 0 & CountDate <= 212)
```

#### Making the lagged data needed for analysis

```{r making lagged data}
data7$CountDate <- as.factor(data7$CountDate)

data7 <- data4 %>% group_by(Kommune) %>% mutate(
  Humid_lag14 = lag(Humid, 14),
  Humid_lag18 = lag(Humid, 18),
  Humid_lag21 = lag(Humid, 21),
  Precip_lag14 = lag(Precip, 14),
  Precip_lag18 = lag(Precip, 18),
  Precip_lag21 = lag(Precip, 21),
  Sun_lag14 = lag(Sun, 14),
  Sun_lag18 = lag(Sun, 18),
  Sun_lag21 = lag(Sun, 21),
  Temp_lag14 = lag(Temp, 14),
  Temp_lag18 = lag(Temp, 18),
  Temp_lag21 = lag(Temp, 21),
  Wind_lag14 = lag(Wind, 14),
  Wind_lag18 = lag(Wind, 18),
  Wind_lag21 = lag(Wind, 21),
  Cases_lag7 = lag(CasePerTest, 7),
  Cases_lag14 = lag(CasePerTest, 14),
  Test_lag7 = lag(Tests, 7),
  Parks_Change_lag = lag(Park, 11),
  Retail_Change_lag = lag(Retail, 11),
  Transit_Change_lag = lag(Transit, 11), 
  Grocery_Change_lag = lag(Grocery, 11),
  Residential_Change_lag = lag(Residential, 11),
  Workplace_Change_lag = lag(Workplace, 11)
  )

data8 <- data7 %>% filter(CountDate >= 30 & CountDate <= 210) #Filtering out dates after i have made lagged data
```

#### Making a variable for months 

```{r Making a variable for months}
d7$Month <- ifelse(d7$CountDate >= 32 & d7$CountDate <= 61, "June",
            ifelse(d7$CountDate >= 62 & d7$CountDate <= 92, "July",
            ifelse(d7$CountDate >= 93 & d7$CountDate <= 123, "August",
            ifelse(d7$CountDate >= 124 & d7$CountDate <= 154, "September",
            ifelse(d7$CountDate >= 155 & d7$CountDate <= 185, "October",
            ifelse(d7$CountDate >= 186 & d7$CountDate <= 210, "November", "å" 
                   ))))))
```

#### Using boruta algorithm to test for which instruments are best

```{r Variable importance plot for instrument of cases lag1 variable}
boruta_output <- Boruta(Cases_lag7 ~ ., data=na.omit(d7), doTrace=2, maxRuns = 30)

# Plot variable importance
plot(boruta_output, cex.axis= 0.7, las=3, xlab="Instrumental Variables", main="Variable Importance")
```


#### Testing IV relevance of the five most valuable variables

```{r Testing IV relevance}
summary(lmerTest::lmer(data = data9, Cases_lag7 ~ Precip_lag14 + Temp_lag14 + Temp_lag21 + Sun_lag18 + Humid_lag14 + (1|Kommune)))
```

#### Testing validity condition with boruta

```{r Variable importance for change variable}
boruta_output2 <- Boruta(CasePerTest ~ ., data=na.omit(data11), doTrace=2, maxRuns = 50)

# Plot variable importance
plot(boruta_output2, cex.axis=.5, las=2, xlab="", main="Variable Importance")

```

#### Getting Danish Statistics integration with devtools

```{r Getting devtools for dkstat}
if(!require("devtools")) install.packages("devtools")

library("devtools")

install_github("rOpenGov/dkstat", force =TRUE )

library(dkstat)

table<- dst_get_tables(lang = "da")

aulaar_meta <- dst_meta(table = "BY3", lang = "da")
```

#### Loading in foreigner data

```{r}
Herkomst <- dst_get_data(table = "EB3" , OPHER = "*",  KØN = "*", ALDER ="*", IELAND = "*", OMRÅDE = "*", Tid = "2020")
Herkomst1 <- dst_get_data(table = "FOLK1E" , OMRÅDE = "*",  KØN = "I alt", ALDER ="I alt", HERKOMST = "*", Tid = "2020K4")

Herkomst2 <- Herkomst1 %>% 
    group_by(OMRÅDE) %>% 
     pivot_wider(., 1, names_from = HERKOMST, values_fn = sum)

Herkomst3 <- Herkomst2[c(-1,-2, -32, -33, -51, -74, -94), ]

Herkomst3$Herkomst_IkkeVestlig <- Herkomst3$`Indvandrere fra ikke-vestlige lande` + Herkomst3$`Efterkommere fra ikke-vestlige lande`

Herkomst3$Herkomst_Vestlig <- Herkomst3$`Indvandrere fra vestlige lande`+ Herkomst3$`Efterkommere fra vestlige lande`

Herkomst3$PercentageForeigners_Ikke <- (Herkomst3$Herkomst_IkkeVestlig/Herkomst3$`Personer med dansk oprindelse`) *100

Herkomst3$PercentageForeigners_vest <- (Herkomst3$Herkomst_Vestlig/Herkomst3$`Personer med dansk oprindelse`) *100

Herkomst4 <- Herkomst3 %>% select(OMRÅDE, PercentageForeigners_Ikke, PercentageForeigners_vest)
names(Herkomst4) <- c("Kommune","PercentageForeignersIkke", "PercentageForeigners_vest")
```

#### Loading in population density from danish statistics

```{r Befolkningstæthed}
BY <- dst_get_data(table = "BY3" , FOLKARTAET = "*",  BYER = "*", Tid ="*")

BY <- subset(BY, value != 0)

vars1 <- str_match(BY$BYER, "(\\d+)-(\\d)(\\d+) (\\w+)")
vars1 <-  as.data.frame(vars1)
vars1 <- vars1[, -1]
vars1 <- vars1[, -2:-3]
names(vars1) <- c("Kommune_Nummer", "Kommune")
BY <- cbind(BY, vars1)
BY$BYER <- NULL


kom <- read.csv("kommune.csv", sep = ";")

kom$Kommune_Nummer <- as.factor(kom$Kommune_Nummer)
kom$Kommune <- as.factor(kom$Kommune)

BY2 <- full_join(BY, kom, by = c("Kommune_Nummer"))

BY2$Kommune.x <- NULL

BY3 <- BY2 %>% 
     filter(TID >= as.Date("2020-01-01")) %>%
     group_by(Kommune.y) %>%
     pivot_wider(., c(2, 4:5), names_from = FOLKARTAET, values_from = value, values_fn = sum)

BY3$NY <- BY3$Folketal/BY3$`Areal (km2)`

BY3$`Befolkningstæthed (km2)` <- NULL

colnames(BY3) <- c("Date", "Kommune_nummer", "Kommune", "Befolkningstal", "Areal", "Befolkningstæthed")

BY3 <- subset(BY3, Kommune != "Christiansø")

BY3$Date <- NULL
BY3$Kommune_nummer <- NULL
```

#### Loading age characteristics from danish statistics

```{r Getting age characteristics}
city <- dst_get_data(table = "BY2" , KOMK = "*", ALDER = "*", KØN = "*", Tid = "2020")
city$ALDER <- gsub("år", "", city$ALDER)

colnames(city) <- c("Kommune", "Alder", "Køn", "Date", "Antal_Gruppe")

city$Alder <- as.numeric(city$Alder)

city <- subset(city, Alder <= 100)

city <- subset(city, Kommune != "Christiansø")

city1 <- city %>% 
     mutate(Alder = ifelse(Alder >= 19 & Alder < 30, "Under_30",
                      ifelse(Alder >= 30 & Alder < 110, "Over_30", "h"))) %>% 
     group_by(Kommune, Alder) %>% 
     summarise(
       Antal = sum(Antal_Gruppe)
     )       
                           

city <- city1 %>% group_by(Kommune, Alder) %>% 
     pivot_wider(., 1:3, names_from = Alder, values_from = Antal) 

city <- city %>% mutate(
       Total = Under_30 + Over_30 + h,
       Under_30 = (Under_30/Total)*100,
       Over_30 = (Over_30/Total)*100)
```

#### Reading in stringency index data 

```{r Reading in stringency index}
string <- read_csv("government_strigency.csv")
string$Date <- as.factor(string$date)
string$date <- NULL
string$location <- NULL

string <- string %>% mutate(
          stringency_index = lag(stringency_index, 11)
            )
```

#### Joining data for analysis and making sure data is filtered aswell

```{r Joining it all for the analysis}

join1 <- full_join(BY3, city, by = c("Kommune"))
join2 <- full_join(join1, gend, by = c("Kommune"))
join3 <- full_join(join2, Ligestil, by = c("Kommune"))
join4 <- full_join(join3, Herkomst4, by = c("Kommune"))


d2 <- full_join(data8, join4, by = c("Kommune"))

string <- full_join(kontakt, string, by = "Date")

d7 <- full_join(d2, string, by = "Date")

d7 <- d7 %>% filter(CountDate >= 30 & CountDate <= 212)

d7$Kontakttal <- d7$Kontakttal.x
d7$Kontakttal.x <- NULL
d7$Kontakttal.y <- NULL

d8 <- d7
```

#### Making a rescaling function

```{r Rescaling function}
z_scale <- function(column){
  column_c <- (column - mean(column, na.rm = T)) / sd(column, na.rm = T)
  return(column_c)
  }
```

#### Rescaling IV variables

```{r Rescaling IV Variables}
d7$Sun_lag18 <- (d7$Sun_lag18 - mean(d7$Sun_lag18, na.rm = T)) / sd(d7$Sun_lag18, na.rm = T)
d7$Sun_lag14 <- (d7$Sun_lag14 - mean(d7$Sun_lag14, na.rm = T)) / sd(d7$Sun_lag14, na.rm = T)
d7$Humid_lag14 <- (d7$Humid_lag14 - mean(d7$Humid_lag14, na.rm = T)) / sd(d7$Humid_lag14, na.rm = T)
d7$Precip_lag14 <- (d7$Precip_lag14 - mean(d7$Precip_lag14, na.rm = T)) / sd(d7$Precip_lag14, na.rm = T)
d7$Precip_lag21 <- (d7$Precip_lag21 - mean(d7$Precip_lag21, na.rm = T)) / sd(d7$Precip_lag21, na.rm = T)
d7$Precip_lag18 <- (d7$Precip_lag18 - mean(d7$Precip_lag18, na.rm = T)) / sd(d7$Precip_lag18, na.rm = T)
d7$Wind_lag14 <- (d7$Wind_lag14 - mean(d7$Wind_lag14, na.rm = T)) / sd(d7$Wind_lag14, na.rm = T)
d7$Wind_lag18 <- (d7$Wind_lag18 - mean(d7$Wind_lag18, na.rm = T)) / sd(d7$Wind_lag18, na.rm = T)
d7$Wind_lag21 <- (d7$Wind_lag21 - mean(d7$Wind_lag21, na.rm = T)) / sd(d7$Wind_lag21, na.rm = T)
d7$Humid_lag21 <- (d7$Humid_lag21 - mean(d7$Humid_lag21, na.rm = T)) / sd(d7$Humid_lag21, na.rm = T)
d7$Cases_lag7 <- (d7$Cases_lag7 - mean(d7$Cases_lag7, na.rm = T)) / sd(d7$Cases_lag7, na.rm = T)
d7$Temp_lag21 <- (d7$Temp_lag21 - mean(d7$Temp_lag21, na.rm = T)) / sd(d7$Temp_lag21, na.rm = T)
d7$Temp_lag14 <- (d7$Temp_lag14 - mean(d7$Temp_lag14, na.rm = T)) / sd(d7$Temp_lag14, na.rm = T)
d7$Temp_lag18 <- (d7$Temp_lag18 - mean(d7$Temp_lag18, na.rm = T)) / sd(d7$Temp_lag18, na.rm = T)
d7$Sun_lag21 <- (d7$Sun_lag21 - mean(d7$Sun_lag21, na.rm = T)) / sd(d7$Sun_lag21, na.rm = T)
d7$Humid_lag18 <- (d7$Humid_lag18 - mean(d7$Humid_lag18, na.rm = T)) / sd(d7$Humid_lag18, na.rm = T)
```

#### Rescaling explanatory variables

```{r Rescaling variables}
d7$CasePerTest <- (d7$CasePerTest - mean(d7$CasePerTest, na.rm = T)) / sd(d7$CasePerTest, na.rm = T)
d7$Test_lag7 <- (d7$Test_lag7 - mean(d7$Test_lag7, na.rm = T)) / sd(d7$Test_lag7, na.rm = T)
d7$Befolkningstal <- (d7$Befolkningstal - mean(d7$Befolkningstal, na.rm = T)) / sd(d7$Befolkningstal, na.rm = T)
d7$Befolkningstæthed <- (d7$Befolkningstæthed - mean(d7$Befolkningstæthed, na.rm = T)) / sd(d7$Befolkningstæthed, na.rm = T)
d7$Areal <- (d7$Areal - mean(d7$Areal, na.rm = T)) / sd(d7$Areal, na.rm = T)
d7$Gennemsnitsløn <- (d7$Gennemsnitsløn - mean(d7$Gennemsnitsløn, na.rm = T)) / sd(d7$Gennemsnitsløn, na.rm = T)
d7$stringency_index <- (d7$stringency_index - mean(d7$stringency_index, na.rm = T)) / sd(d7$stringency_index, na.rm = T)
d7$Under_30 <- (d7$Under_30 - mean(d7$Under_30, na.rm = T)) / sd(d7$Under_30, na.rm = T)
d7$Over_30 <- (d7$Over_30 - mean(d7$Over_30, na.rm = T)) / sd(d7$Over_30, na.rm = T)
d7$PercentageForeigners_vest <- (d7$PercentageForeigners_vest - mean(d7$PercentageForeigners_vest, na.rm = T)) / sd(d7$PercentageForeigners_vest, na.rm = T)
d7$PercentageForeignersIkke <- (d7$PercentageForeignersIkke - mean(d7$PercentageForeignersIkke, na.rm = T)) / sd(d7$PercentageForeignersIkke, na.rm = T)
d7$Parks_Change_lag <- (d7$Parks_Change_lag - mean(d7$Parks_Change_lag, na.rm = T)) / sd(d7$Parks_Change_lag, na.rm = T)
d7$Retail_Change_lag <- (d7$Retail_Change_lag - mean(d7$Retail_Change_lag, na.rm = T)) / sd(d7$Retail_Change_lag, na.rm = T)
d7$Transit_Change_lag <- (d7$Transit_Change_lag - mean(d7$Transit_Change_lag, na.rm = T)) / sd(d7$Transit_Change_lag, na.rm = T)
d7$Grocery_Change_lag <- (d7$Grocery_Change_lag - mean(d7$Grocery_Change_lag, na.rm = T)) / sd(d7$Grocery_Change_lag, na.rm = T)
d7$Residential_Change_lag <- (d7$Residential_Change_lag - mean(d7$Residential_Change_lag, na.rm = T)) / sd(d7$Residential_Change_lag, na.rm = T)
d7$Workplace_Change_lag <- (d7$Workplace_Change_lag - mean(d7$Workplace_Change_lag, na.rm = T)) / sd(d7$Workplace_Change_lag, na.rm = T)
d7$Cases <- (d7$Cases - mean(d7$Cases, na.rm = T)) / sd(d7$Cases, na.rm = T)
d7$Tests <- (d7$Tests - mean(d7$Tests, na.rm = T)) / sd(d7$Tests, na.rm = T)
```

### Running 2SLS
#### Running first stage of the 2SLS

```{r Running 1. stage of 2SLS}
IV2SLS2 <- lm(data = d7, Cases_lag7 ~ stringency_index + Under_30 + PercentageForeignersIkke + Befolkningstæthed + PercentageForeigners_vest + Retail_Change_lag + Transit_Change_lag + Grocery_Change_lag + Residential_Change_lag + Precip_lag14 + Temp_lag14 + Temp_lag21 + Sun_lag18 + Humid_lag14, na.action = na.exclude)

d7$Fitted2 <- fitted(IV2SLS2)
```

#### Running second stage of the 2SLS

```{r}
Regression3 <- lm(data = d7, CasePerTest ~ Fitted2 + stringency_index + Under_30 + PercentageForeignersIkke + PercentageForeigners_vest + Retail_Change_lag + Transit_Change_lag + Grocery_Change_lag + Befolkningstæthed + Residential_Change_lag, REML = F, control = lmerControl(optimizer = "nloptwrap", calc.derivs = FALSE), na.action = na.exclude)
Summary(Regression3)
```

#### Running regression without fixed effects

```{r }
Regression1 <- lm(data = d7, CasePerTest ~ stringency_index + Under_30 + PercentageForeignersIkke + PercentageForeigners_vest + Retail_Change_lag + Transit_Change_lag + Grocery_Change_lag + Befolkningstæthed + Residential_Change_lag, REML = F, control = lmerControl(optimizer = "nloptwrap", calc.derivs = FALSE), na.action = na.exclude)
```

#### Testing for poolability

```{r}
RSS_R <- sum(regression3$residuals^2)
RSS_U <- sum(regression$residuals^2)

DOFF1 <- 98+181-2
DOFF2 <- 17839

F_test <- ((RSS_R- RSS_U)/DOFF1) /(RSS_U/DOFF2)
F_test
pf(F_test, DOFF1, DOFF2, lower.tail = F)
```

### Making function to destandardize variables for interpretability

```{r Destandardize variables}

destandardize <- function(coefficient, x, y){
        d =  ((coefficient*sd(y, na.rm = T)) / sd(x, na.rm = T) )
        return(d)
        }

destandardize(5.812e-01, d8$Cases_lag7, d8$CasePerTest)
destandardize(-1.954e-01, d8$stringency_index, d8$CasePerTest)
destandardize(6.322e-02, d8$Retail_Change_lag, d8$CasePerTest)
destandardize(2.785e-02, d8$Under_30, d8$CasePerTest)
destandardize(7.276e-02, d8$PercentageForeignersIkke, d8$CasePerTest)
```

### Making plot

```{r}
ggline(d8,
       x = "Month",
       y = "CasePerTest",
       col = "Region",
       add = c("mean_se", "dodge"),
       palette = "jco")
```


